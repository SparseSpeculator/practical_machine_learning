---
title: "Predicting Motions from Human Activity Recognition Data"
author: "Sebastian Ruecker"
date: "20 August 2018"
output: html_document
---

```{r setup, include=FALSE, echo=FALSE}
rm(list=ls())
library(rpart)
library(party)
library(tidyverse)
library(caret)
library(doParallel)
library(dplyr)
library(Amelia)
setwd("Z:/Coursera/Practical Machine Learning/Final machine learning")

if (file.exists("pml_training.csv") == FALSE) {
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml_training.csv")
}
if (file.exists("pml_testing.csv") == FALSE) {
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml_testing.csv")
}
col_spec_train <- cols(
  .default = col_double(),
  X1 = col_integer(),
  classe = col_character(),
  user_name = col_character(),
  raw_timestamp_part_1 = col_integer(),
  raw_timestamp_part_2 = col_integer(),
  cvtd_timestamp = col_character(),
  new_window = col_character()
)
col_spec_test <- cols(
  .default = col_double(),
  X1 = col_integer(),
  user_name = col_character(),
  raw_timestamp_part_1 = col_integer(),
  raw_timestamp_part_2 = col_integer(),
  cvtd_timestamp = col_character(),
  new_window = col_character()
)

set.seed(1)
```

## Data
We used Data from the Human Activity Recognition Data available here: <http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har>

Personal fitness devices were used by 6 users to record their movements. From these data we estimate which of 5 different motions they performed. The data consists of sensor data for movements along various axis.

## Preprocessing
```{r, include=FALSE, echo=FALSE}
pml_training_raw <- read_csv("pml_training.csv", na = c("#DIV/0!", "", "NA"), trim_ws = TRUE, col_types = col_spec_train)
pml_testing_raw <- read_csv("pml_testing.csv", na = c("#DIV/0!", "", "NA"), trim_ws = TRUE, col_types = col_spec_test)

pml_training <- dplyr::rename(pml_training_raw,
                              user_ = user_name,
                              class = classe,
                              kurtosis_pitch_arm = kurtosis_picth_arm,
                              kurtosis_pitch_belt = kurtosis_picth_belt,
                              kurtosis_pitch_dumbbell = kurtosis_picth_dumbbell,
                              kurtosis_pitch_forearm = kurtosis_picth_forearm) %>% 
  dplyr::mutate(user_ = factor(user_), class = factor(class)) %>%
  cbind(., 
        predict(dummyVars(~ user_, data =.),newdata=.)) %>%
  dplyr::select(class, starts_with("user"), everything(), -starts_with("raw_t"), -cvtd_timestamp, -num_window, -new_window, -user_, -num_window, -X1)

pml_testing <- dplyr::rename(pml_testing_raw,
                             user_ = user_name,
                             kurtosis_pitch_arm = kurtosis_picth_arm,
                             kurtosis_pitch_belt = kurtosis_picth_belt,
                             kurtosis_pitch_dumbbell = kurtosis_picth_dumbbell,
                             kurtosis_pitch_forearm = kurtosis_picth_forearm) %>% 
  dplyr::mutate(user_ = factor(user_)) %>%
  cbind(., 
        predict(dummyVars(~ user_, data =.),newdata=.)) %>%
  dplyr::select(starts_with("user"), everything(), -starts_with("raw_t"), -cvtd_timestamp, -num_window, -new_window, -user_, -num_window, -X1)
```

19622 records data are available for analysis. All columns with more than 90% percent of missing values were removed, leaving 58 columns of explatory variables: the six dummy variables for the different users plus 52 columns of sensor readings. The remaining data contain no more missing values

```{r}
missing_perc <- data.frame(train=sort(apply(pml_training, 2, FUN=function(x) mean(is.na(x)))),
                           test=sort(apply(pml_testing, 2, FUN=function(x) mean(is.na(x)))))
pml_training_prune <- pml_training[,rownames(missing_perc)[missing_perc$train<.9]]
pml_testing_prune <- pml_testing[,rownames(missing_perc)[missing_perc$train<.9][-1]]

anyNA(pml_training_prune) | anyNA(pml_training_prune)
```

We split the data into test-set and training-set, using 80% of available data for training. 
Since the data contain a large number of mutually depedant variables, we use PCA to reduce the number of variables and to eliminate multicolinearity.

```{r}
prep <- preProcess(pml_training_prune, method="pca")
prep_training <- predict(prep, pml_training_prune) 
```

## Modelling
With the resulting training set, several models were built. The used models were:

* Random Forest (rfo)
* Penalized Multinomial Regression (mul)
* Stochastic Gradient Boosting (gbm)
* Neural Network (rnn)
* K-Nearest-Neighbour-Classification (knn)

We use 3-fold cros validation for the random forest. To save computation time, we don't use cross validation for the other models.

```{r, include=FALSE, echo=FALSE}
train_idx <- createDataPartition(prep_training$class, p=.8, list = FALSE)
dtrain <- prep_training[train_idx,]
dtest <- prep_training[-train_idx,]

cores <- detectCores()
cl <- makeCluster(cores)
registerDoParallel(cl)
train_control <- trainControl(method="cv", number=3, savePredictions = TRUE)

m_rfo <- train(class~., data = dtrain, metric="Accuracy", method="rf", trControl = train_control)
m_mul <- train(class~., data = dtrain, method="multinom", verbose=FALSE)
m_gbm <- train(class~., data = dtrain, method="gbm", verbose=FALSE)
m_rnn <- train(class~., data = dtrain, method="nnet", verbose=FALSE)
m_knn <- knn3(class~., data = dtrain)

stopCluster(cl)
registerDoSEQ()

cm_m_knn <- confusionMatrix(dtest$class,factor(apply(predict(m_knn, dtest), 1, which.max), labels=c("A", "B", "C", "D", "E")))
cm_m_gbm <- confusionMatrix(dtest$class,factor(apply(predict(m_gbm$finalModel, dtest, n.trees = 1), 1, which.max), labels=c("A", "B", "C", "D", "E")))
cm_m_rnn <- confusionMatrix(dtest$class,factor(apply(predict(m_rnn$finalModel, dtest), 1, which.max), labels=c("A", "B", "C", "D", "E")))
cm_m_rfo <- confusionMatrix(dtest$class,predict(m_rfo$finalModel, dtest))
cm_m_mul <- confusionMatrix(dtest$class,predict(m_mul$finalModel, dtest))
model_stats <- t(data_frame(
  knn=cm_m_knn$overall,
  gbm=cm_m_gbm$overall, 
  rnn=cm_m_rnn$overall, 
  rfo=cm_m_rfo$overall, 
  mul=cm_m_mul$overall))
methods <- rownames(model_stats)
colnames(model_stats) <- names(cm_m_gbm$overall)
as_data_frame(model_stats) %>% 
  mutate(m = methods) %>% 
  select(m, everything()) %>% 
  arrange(-Accuracy)
```

## Analysis
As we see, the models perform quite differently on the test dataset. The best accuracy (97,88%) is achieved by the random forest, followed by the nearest neighbour classification (96,58%).
```{r}
model_stats
```

We take a closer look at the performance of the random forest and see, that it performs well over all categories.

```{r, echo=FALSE}
cm = confusionMatrix(dtest$class,factor(predict(m_rfo$finalModel, dtest)))
cm
```
A detailled look into accuracy and recall reveals, that the model has the lowest recall for category C and the lowest accuracy for category D. Since both values are above 95% for test data, less than one in twenty motions are misclassified.
```{r, echo=FALSE}
as_data_frame(cm$table) %>% 
  mutate(correct=Prediction==Reference) %>% 
  group_by(Prediction) %>% 
  mutate(pred_sum=sum(n), accuracy=n*correct/pred_sum) %>% 
  ungroup() %>% 
  group_by(Reference) %>%  
  mutate(ref_sum=sum(n), recall=n*correct/ref_sum) %>% 
  ungroup() %>%
  filter(Prediction == Reference) %>% select(class=Prediction,accuracy, recall)
```
## Conclusion
We conclude, that random forests can reliably predict motions from sensor data that has been preprocessed by PCA.